{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\StonyBrook\\Study\\Prob&Stats CSE544\\Project\n"
     ]
    }
   ],
   "source": [
    "%cd D:\\StonyBrook\\Study\\Prob&Stats CSE544\\Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('7.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## converting date column to datetime data type ##\n",
    "data['Date'] = pd.to_datetime(data['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>IA confirmed cumulative</th>\n",
       "      <th>ID confirmed cumulative</th>\n",
       "      <th>IA deaths cumulative</th>\n",
       "      <th>ID deaths cumulative</th>\n",
       "      <th>IA confirmed</th>\n",
       "      <th>ID confirmed</th>\n",
       "      <th>IA deaths</th>\n",
       "      <th>ID deaths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>2021-03-30</td>\n",
       "      <td>349742</td>\n",
       "      <td>179429</td>\n",
       "      <td>5726</td>\n",
       "      <td>1956</td>\n",
       "      <td>141.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>2021-03-31</td>\n",
       "      <td>350840</td>\n",
       "      <td>180536</td>\n",
       "      <td>5744</td>\n",
       "      <td>1962</td>\n",
       "      <td>1098.0</td>\n",
       "      <td>1107.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>351651</td>\n",
       "      <td>180897</td>\n",
       "      <td>5744</td>\n",
       "      <td>1963</td>\n",
       "      <td>811.0</td>\n",
       "      <td>361.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>2021-02-04</td>\n",
       "      <td>352262</td>\n",
       "      <td>181181</td>\n",
       "      <td>5752</td>\n",
       "      <td>1966</td>\n",
       "      <td>611.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>2021-03-04</td>\n",
       "      <td>352813</td>\n",
       "      <td>181181</td>\n",
       "      <td>5755</td>\n",
       "      <td>1966</td>\n",
       "      <td>551.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>438 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  IA confirmed cumulative  ID confirmed cumulative  \\\n",
       "0   2020-01-22                        0                        0   \n",
       "1   2020-01-23                        0                        0   \n",
       "2   2020-01-24                        0                        0   \n",
       "3   2020-01-25                        0                        0   \n",
       "4   2020-01-26                        0                        0   \n",
       "..         ...                      ...                      ...   \n",
       "433 2021-03-30                   349742                   179429   \n",
       "434 2021-03-31                   350840                   180536   \n",
       "435 2021-01-04                   351651                   180897   \n",
       "436 2021-02-04                   352262                   181181   \n",
       "437 2021-03-04                   352813                   181181   \n",
       "\n",
       "     IA deaths cumulative  ID deaths cumulative  IA confirmed  ID confirmed  \\\n",
       "0                       0                     0           NaN           NaN   \n",
       "1                       0                     0           0.0           0.0   \n",
       "2                       0                     0           0.0           0.0   \n",
       "3                       0                     0           0.0           0.0   \n",
       "4                       0                     0           0.0           0.0   \n",
       "..                    ...                   ...           ...           ...   \n",
       "433                  5726                  1956         141.0           0.0   \n",
       "434                  5744                  1962        1098.0        1107.0   \n",
       "435                  5744                  1963         811.0         361.0   \n",
       "436                  5752                  1966         611.0         284.0   \n",
       "437                  5755                  1966         551.0           0.0   \n",
       "\n",
       "     IA deaths  ID deaths  \n",
       "0          NaN        NaN  \n",
       "1          0.0        0.0  \n",
       "2          0.0        0.0  \n",
       "3          0.0        0.0  \n",
       "4          0.0        0.0  \n",
       "..         ...        ...  \n",
       "433        7.0        0.0  \n",
       "434       18.0        6.0  \n",
       "435        0.0        1.0  \n",
       "436        8.0        3.0  \n",
       "437        3.0        0.0  \n",
       "\n",
       "[438 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 438 entries, 0 to 437\n",
      "Data columns (total 9 columns):\n",
      " #   Column                   Non-Null Count  Dtype         \n",
      "---  ------                   --------------  -----         \n",
      " 0   Date                     438 non-null    datetime64[ns]\n",
      " 1   IA confirmed cumulative  438 non-null    int64         \n",
      " 2   ID confirmed cumulative  438 non-null    int64         \n",
      " 3   IA deaths cumulative     438 non-null    int64         \n",
      " 4   ID deaths cumulative     438 non-null    int64         \n",
      " 5   IA confirmed             437 non-null    float64       \n",
      " 6   ID confirmed             437 non-null    float64       \n",
      " 7   IA deaths                437 non-null    float64       \n",
      " 8   ID deaths                437 non-null    float64       \n",
      "dtypes: datetime64[ns](1), float64(4), int64(4)\n",
      "memory usage: 30.9 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    }
   ],
   "source": [
    "###### Feb and March data #######\n",
    "feb_start_date , feb_end_date = '2021-02-01', '2021-02-28'\n",
    "march_start_date, march_end_date = '2021-03-01', '2021-03-31'\n",
    "condition = (data['Date'] >= feb_start_date) & (data['Date'] <= feb_end_date)\n",
    "feb_data = data.loc[condition]\n",
    "\n",
    "condition = (data['Date'] >= march_start_date) & (data['Date'] <= march_end_date)\n",
    "march_data = data.loc[condition]\n",
    "\n",
    "print(len(march_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Tests for IA confirmed cases handle ###################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLE for March data  539.695652173913\n",
      "Guess mean  547.0\n",
      "Standard Error  4.844071464727531\n",
      "Walds Statistic 1.5078943156132505\n"
     ]
    }
   ],
   "source": [
    "handle = 'IA confirmed'\n",
    "mean_feb = np.mean(feb_data[handle])\n",
    "\n",
    "## Using mean_feb as guess for mean_march ##\n",
    "\n",
    "# Wald's test # \n",
    "# w = (theta_hat - theta_0)/ se_hat(theta_hat)\n",
    "# theta_hat is estimator of theta\n",
    "\n",
    "# Null Hypothesis : mean_march = mean_feb\n",
    "# Alternate Hypothesis : mean_march != mean_feb\n",
    "\n",
    "# Assuming the distribution of march data to be poisson. MLE_mean = Sample_mean\n",
    "\n",
    "sample_mean_march = np.mean(march_data[handle])\n",
    "\n",
    "standard_error_estimate = np.sqrt(sample_mean_march/len(march_data))\n",
    "\n",
    "walds_statistic = np.abs((sample_mean_march - mean_feb)/standard_error_estimate)\n",
    "\n",
    "print('MLE for March data ',sample_mean_march )\n",
    "print('Guess mean ', mean_feb)\n",
    "print('Standard Error ', standard_error_estimate)\n",
    "print('Walds Statistic', walds_statistic )\n",
    "\n",
    "# Accept Null Hypothesis(less than 1.96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " True Variance  120109.94861660078\n",
      " Sample Mean  539.695652173913\n",
      " Guess  547.0\n",
      " z_statistic  0.10107782149960952\n"
     ]
    }
   ],
   "source": [
    "## Z-test ##\n",
    "\n",
    "# z_statistic = (sample_mean - guess)/ root(true_variance/n)\n",
    "# true variance = corrected sample standard deviation\n",
    "\n",
    "true_variance = np.sum(np.square(march_data[handle] - sample_mean_march))/(len(march_data)-1)\n",
    "\n",
    "z_statistic = np.abs((sample_mean_march - mean_feb)/(np.sqrt(true_variance)/np.sqrt(len(march_data))))\n",
    "\n",
    "print(' True Variance ', true_variance)\n",
    "print(' Sample Mean ',sample_mean_march )\n",
    "print(' Guess ', mean_feb)\n",
    "print(' z_statistic ', z_statistic)\n",
    "\n",
    "\n",
    "# Accept Null Hypothesis(less than 1.96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Corrected Sample Standard Deviation 346.5688223377873\n",
      " Sample Mean  539.695652173913\n",
      " Guess  547.0\n",
      " t_statistic  0.10107782149960952\n"
     ]
    }
   ],
   "source": [
    "## t-test ##\n",
    "\n",
    "# t_statistic = (sample_mean - guess)/ corrected_sample_standard_deviation/root(n)\n",
    "corrected_sample_SD = np.sqrt(np.sum(np.square(march_data[handle] - sample_mean_march))/(len(march_data)-1))\n",
    "\n",
    "t_statistic = np.abs((sample_mean_march - mean_feb)/(corrected_sample_SD/np.sqrt(len(march_data))))\n",
    "\n",
    "print(' Corrected Sample Standard Deviation', corrected_sample_SD)\n",
    "print(' Sample Mean ',sample_mean_march )\n",
    "print(' Guess ', mean_feb)\n",
    "print(' t_statistic ', t_statistic)\n",
    "\n",
    "# degrees of freedom : 28 + 31 -2 = 57\n",
    "# threshold = 2.002465\n",
    "\n",
    "# Accept Null Hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Standard Error Estimate 0.6054689319851547\n",
      " Delta Estimate  2.2108695652173913\n",
      " w_stat  3.651499603734579\n"
     ]
    }
   ],
   "source": [
    "## Walds - 2 sample test ##\n",
    "\n",
    "# delta = mean_march - mean_feb \n",
    "\n",
    "# w_stat = delta_hat/ SE_hat(delta_hat)\n",
    "\n",
    "# Assumption : Data is poisson distributed\n",
    "\n",
    "# Null Hypothesis : delta = 0\n",
    "# Alternate Hypothesis : delta != 0 \n",
    "\n",
    "\n",
    "sample_mean_march = np.mean(march_data[handle])\n",
    "sample_mean_feb = np.mean(feb_data[handle])\n",
    "\n",
    "delta_hat = np.abs(sample_mean_march - sample_mean_feb)\n",
    "\n",
    "SE_hat = np.sqrt(sample_mean_march/len(march_data) + sample_mean_feb/len(feb_data))\n",
    "\n",
    "w_stat = np.abs(delta_hat/SE_hat)\n",
    "\n",
    "print(' Standard Error Estimate', SE_hat)\n",
    "print(' Delta Estimate ',delta_hat )\n",
    "print(' w_stat ', w_stat)\n",
    "\n",
    "# Accept Null Hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Corrected Variance March 11.38339920948616\n",
      " Corrected Variance Feb 28.99736842105264\n",
      " D bar 2.2108695652173913\n",
      " t_statistic  1.585352274044677\n"
     ]
    }
   ],
   "source": [
    "## 2 sample unpaired t-test ##\n",
    "\n",
    "# D_bar = X_bar - Y_bar\n",
    "# t_stat = D_bar/root(corrected_var_x/n + corrected_var_y/m)\n",
    "\n",
    "corrected_variance_march = np.sum(np.square(march_data[handle] - sample_mean_march))/(len(march_data)-1)\n",
    "corrected_variance_feb =  np.sum(np.square(feb_data[handle] - sample_mean_feb))/(len(feb_data)-1)\n",
    "\n",
    "D_bar = np.abs(sample_mean_march - sample_mean_feb)\n",
    "\n",
    "t_stat = D_bar/np.sqrt(corrected_variance_march/len(march_data) + corrected_variance_feb/len(feb_data))\n",
    "\n",
    "print(' Corrected Variance March', corrected_variance_march)\n",
    "print(' Corrected Variance Feb', corrected_variance_feb)\n",
    "print(' D bar',D_bar )\n",
    "print(' t_statistic ', t_stat)\n",
    "\n",
    "# threshold = 2.002465\n",
    "\n",
    "# Accept Null Hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Tests for IA death cases handle ###################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Walds test\n",
      "MLE for March data  7.565217391304348\n",
      "Guess mean  17.15\n",
      "Standard Error  0.5735176503596922\n",
      "Walds Statistic 16.71227137069692\n",
      "########################################\n",
      "Z test\n",
      " True Variance  159.25691699604744\n",
      " Sample Mean  7.565217391304348\n",
      " Guess  17.15\n",
      " z_statistic  3.642478802841167\n",
      "########################################\n",
      "T-test\n",
      " Corrected Sample Standard Deviation 12.619703522509846\n",
      " Sample Mean  7.565217391304348\n",
      " Guess  17.15\n",
      " t_statistic  3.642478802841167\n",
      "########################################\n",
      "Walds - 2 sample test\n",
      " Standard Error Estimate 1.0892302306097192\n",
      " Delta Estimate  9.584782608695651\n",
      " w_stat  8.799592904550924\n",
      "########################################\n",
      "2 sample unpaired t-test \n",
      " Corrected Variance March 159.25691699604744\n",
      " Corrected Variance Feb 209.50263157894736\n",
      " D bar 9.584782608695651\n",
      " t_statistic  2.297818982516213\n",
      "########################################\n"
     ]
    }
   ],
   "source": [
    "handle = 'IA deaths'\n",
    "mean_feb = np.mean(feb_data[handle])\n",
    "\n",
    "## Using mean_feb as guess for mean_march ##\n",
    "\n",
    "# Wald's test # \n",
    "# w = (theta_hat - theta_0)/ se_hat(theta_hat)\n",
    "# theta_hat is estimator of theta\n",
    "\n",
    "# Null Hypothesis : mean_march = mean_feb\n",
    "# Alternate Hypothesis : mean_march != mean_feb\n",
    "\n",
    "# Assuming the distribution of march data to be poisson. MLE_mean = Sample_mean\n",
    "\n",
    "sample_mean_march = np.mean(march_data[handle])\n",
    "\n",
    "standard_error_estimate = np.sqrt(sample_mean_march/len(march_data))\n",
    "\n",
    "walds_statistic = np.abs((sample_mean_march - mean_feb)/standard_error_estimate)\n",
    "\n",
    "print('Walds test')\n",
    "print('MLE for March data ',sample_mean_march )\n",
    "print('Guess mean ', mean_feb)\n",
    "print('Standard Error ', standard_error_estimate)\n",
    "print('Walds Statistic', walds_statistic )\n",
    "\n",
    "# Reject Null Hypothesis(greater than 1.96)\n",
    "print('########################################')\n",
    "\n",
    "\n",
    "## Z-test ##\n",
    "\n",
    "# z_statistic = (sample_mean - guess)/ root(true_variance/n)\n",
    "# true variance = corrected sample standard deviation\n",
    "\n",
    "true_variance = np.sum(np.square(march_data[handle] - sample_mean_march))/(len(march_data)-1)\n",
    "\n",
    "z_statistic = np.abs((sample_mean_march - mean_feb)/(np.sqrt(true_variance)/np.sqrt(len(march_data))))\n",
    "\n",
    "print('Z test')\n",
    "print(' True Variance ', true_variance)\n",
    "print(' Sample Mean ',sample_mean_march )\n",
    "print(' Guess ', mean_feb)\n",
    "print(' z_statistic ', z_statistic)\n",
    "\n",
    "\n",
    "# Reject Null Hypothesis(greater than 1.96)\n",
    "\n",
    "print('########################################')\n",
    "\n",
    "\n",
    "## t-test ##\n",
    "\n",
    "# t_statistic = (sample_mean - guess)/ corrected_sample_standard_deviation/root(n)\n",
    "corrected_sample_SD = np.sqrt(np.sum(np.square(march_data[handle] - sample_mean_march))/(len(march_data)-1))\n",
    "\n",
    "t_statistic = np.abs((sample_mean_march - mean_feb)/(corrected_sample_SD/np.sqrt(len(march_data))))\n",
    "\n",
    "print('T-test')\n",
    "print(' Corrected Sample Standard Deviation', corrected_sample_SD)\n",
    "print(' Sample Mean ',sample_mean_march )\n",
    "print(' Guess ', mean_feb)\n",
    "print(' t_statistic ', t_statistic)\n",
    "\n",
    "# degrees of freedom : 28 + 31 -2 = 57\n",
    "# threshold = 2.002465\n",
    "\n",
    "# Reject Null Hypothesis\n",
    "\n",
    "print('########################################')\n",
    "\n",
    "## Walds - 2 sample test ##\n",
    "\n",
    "# delta = mean_march - mean_feb \n",
    "\n",
    "# w_stat = delta_hat/ SE_hat(delta_hat)\n",
    "\n",
    "# Assumption : Data is poisson distributed\n",
    "\n",
    "# Null Hypothesis : delta = 0\n",
    "# Alternate Hypothesis : delta != 0 \n",
    "\n",
    "\n",
    "sample_mean_march = np.mean(march_data[handle])\n",
    "sample_mean_feb = np.mean(feb_data[handle])\n",
    "\n",
    "delta_hat = np.abs(sample_mean_march - sample_mean_feb)\n",
    "\n",
    "SE_hat = np.sqrt(sample_mean_march/len(march_data) + sample_mean_feb/len(feb_data))\n",
    "\n",
    "w_stat = np.abs(delta_hat/SE_hat)\n",
    "\n",
    "print('Walds - 2 sample test')\n",
    "print(' Standard Error Estimate', SE_hat)\n",
    "print(' Delta Estimate ',delta_hat )\n",
    "print(' w_stat ', w_stat)\n",
    "\n",
    "# Reject Null Hypothesis\n",
    "\n",
    "print('########################################')\n",
    "\n",
    "## 2 sample unpaired t-test ##\n",
    "\n",
    "# D_bar = X_bar - Y_bar\n",
    "# t_stat = D_bar/root(corrected_var_x/n + corrected_var_y/m)\n",
    "\n",
    "corrected_variance_march = np.sum(np.square(march_data[handle] - sample_mean_march))/(len(march_data)-1)\n",
    "corrected_variance_feb =  np.sum(np.square(feb_data[handle] - sample_mean_feb))/(len(feb_data)-1)\n",
    "\n",
    "D_bar = np.abs(sample_mean_march - sample_mean_feb)\n",
    "\n",
    "t_stat = D_bar/np.sqrt(corrected_variance_march/len(march_data) + corrected_variance_feb/len(feb_data))\n",
    "\n",
    "print('2 sample unpaired t-test ')\n",
    "print(' Corrected Variance March', corrected_variance_march)\n",
    "print(' Corrected Variance Feb', corrected_variance_feb)\n",
    "print(' D bar',D_bar )\n",
    "print(' t_statistic ', t_stat)\n",
    "\n",
    "# threshold = 2.002465\n",
    "\n",
    "# Reject Null Hypothesis\n",
    "\n",
    "print('########################################')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Tests for ID confirmed cases handle ###################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Walds test\n",
      "MLE for March data  298.0869565217391\n",
      "Guess mean  333.5\n",
      "Standard Error  3.6000420077364264\n",
      "Walds Statistic 9.836841737446083\n",
      "########################################\n",
      "Z test\n",
      " True Variance  68946.26482213438\n",
      " Sample Mean  298.0869565217391\n",
      " Guess  333.5\n",
      " z_statistic  0.6468026626311423\n",
      "########################################\n",
      "T-test\n",
      " Corrected Sample Standard Deviation 262.57620764672185\n",
      " Sample Mean  298.0869565217391\n",
      " Guess  333.5\n",
      " t_statistic  0.6468026626311423\n",
      "########################################\n",
      "Walds - 2 sample test\n",
      " Standard Error Estimate 5.443831597089216\n",
      " Delta Estimate  35.413043478260875\n",
      " w_stat  6.50516880375139\n",
      "########################################\n",
      "2 sample unpaired t-test \n",
      " Corrected Variance March 68946.26482213438\n",
      " Corrected Variance Feb 95833.0\n",
      " D bar 35.413043478260875\n",
      " t_statistic  0.40124871600151857\n",
      "########################################\n"
     ]
    }
   ],
   "source": [
    "handle = 'ID confirmed'\n",
    "mean_feb = np.mean(feb_data[handle])\n",
    "\n",
    "## Using mean_feb as guess for mean_march ##\n",
    "\n",
    "# Wald's test # \n",
    "# w = (theta_hat - theta_0)/ se_hat(theta_hat)\n",
    "# theta_hat is estimator of theta\n",
    "\n",
    "# Null Hypothesis : mean_march = mean_feb\n",
    "# Alternate Hypothesis : mean_march != mean_feb\n",
    "\n",
    "# Assuming the distribution of march data to be poisson. MLE_mean = Sample_mean\n",
    "\n",
    "sample_mean_march = np.mean(march_data[handle])\n",
    "\n",
    "standard_error_estimate = np.sqrt(sample_mean_march/len(march_data))\n",
    "\n",
    "walds_statistic = np.abs((sample_mean_march - mean_feb)/standard_error_estimate)\n",
    "\n",
    "print('Walds test')\n",
    "print('MLE for March data ',sample_mean_march )\n",
    "print('Guess mean ', mean_feb)\n",
    "print('Standard Error ', standard_error_estimate)\n",
    "print('Walds Statistic', walds_statistic )\n",
    "\n",
    "# Reject Null Hypothesis(greater than 1.96)\n",
    "print('########################################')\n",
    "\n",
    "\n",
    "## Z-test ##\n",
    "\n",
    "# z_statistic = (sample_mean - guess)/ root(true_variance/n)\n",
    "# true variance = corrected sample standard deviation\n",
    "\n",
    "true_variance = np.sum(np.square(march_data[handle] - sample_mean_march))/(len(march_data)-1)\n",
    "\n",
    "z_statistic = np.abs((sample_mean_march - mean_feb)/(np.sqrt(true_variance)/np.sqrt(len(march_data))))\n",
    "\n",
    "print('Z test')\n",
    "print(' True Variance ', true_variance)\n",
    "print(' Sample Mean ',sample_mean_march )\n",
    "print(' Guess ', mean_feb)\n",
    "print(' z_statistic ', z_statistic)\n",
    "\n",
    "\n",
    "# Reject Null Hypothesis(greater than 1.96)\n",
    "\n",
    "print('########################################')\n",
    "\n",
    "\n",
    "## t-test ##\n",
    "\n",
    "# t_statistic = (sample_mean - guess)/ corrected_sample_standard_deviation/root(n)\n",
    "corrected_sample_SD = np.sqrt(np.sum(np.square(march_data[handle] - sample_mean_march))/(len(march_data)-1))\n",
    "\n",
    "t_statistic = np.abs((sample_mean_march - mean_feb)/(corrected_sample_SD/np.sqrt(len(march_data))))\n",
    "\n",
    "print('T-test')\n",
    "print(' Corrected Sample Standard Deviation', corrected_sample_SD)\n",
    "print(' Sample Mean ',sample_mean_march )\n",
    "print(' Guess ', mean_feb)\n",
    "print(' t_statistic ', t_statistic)\n",
    "\n",
    "# degrees of freedom : 28 + 31 -2 = 57\n",
    "# threshold = 2.002465\n",
    "\n",
    "# Reject Null Hypothesis\n",
    "\n",
    "print('########################################')\n",
    "\n",
    "## Walds - 2 sample test ##\n",
    "\n",
    "# delta = mean_march - mean_feb \n",
    "\n",
    "# w_stat = delta_hat/ SE_hat(delta_hat)\n",
    "\n",
    "# Assumption : Data is poisson distributed\n",
    "\n",
    "# Null Hypothesis : delta = 0\n",
    "# Alternate Hypothesis : delta != 0 \n",
    "\n",
    "\n",
    "sample_mean_march = np.mean(march_data[handle])\n",
    "sample_mean_feb = np.mean(feb_data[handle])\n",
    "\n",
    "delta_hat = np.abs(sample_mean_march - sample_mean_feb)\n",
    "\n",
    "SE_hat = np.sqrt(sample_mean_march/len(march_data) + sample_mean_feb/len(feb_data))\n",
    "\n",
    "w_stat = np.abs(delta_hat/SE_hat)\n",
    "\n",
    "print('Walds - 2 sample test')\n",
    "print(' Standard Error Estimate', SE_hat)\n",
    "print(' Delta Estimate ',delta_hat )\n",
    "print(' w_stat ', w_stat)\n",
    "\n",
    "# Reject Null Hypothesis\n",
    "\n",
    "print('########################################')\n",
    "\n",
    "## 2 sample unpaired t-test ##\n",
    "\n",
    "# D_bar = X_bar - Y_bar\n",
    "# t_stat = D_bar/root(corrected_var_x/n + corrected_var_y/m)\n",
    "\n",
    "corrected_variance_march = np.sum(np.square(march_data[handle] - sample_mean_march))/(len(march_data)-1)\n",
    "corrected_variance_feb =  np.sum(np.square(feb_data[handle] - sample_mean_feb))/(len(feb_data)-1)\n",
    "\n",
    "D_bar = np.abs(sample_mean_march - sample_mean_feb)\n",
    "\n",
    "t_stat = D_bar/np.sqrt(corrected_variance_march/len(march_data) + corrected_variance_feb/len(feb_data))\n",
    "\n",
    "print('2 sample unpaired t-test ')\n",
    "print(' Corrected Variance March', corrected_variance_march)\n",
    "print(' Corrected Variance Feb', corrected_variance_feb)\n",
    "print(' D bar',D_bar )\n",
    "print(' t_statistic ', t_stat)\n",
    "\n",
    "# threshold = 2.002465\n",
    "\n",
    "# Reject Null Hypothesis\n",
    "\n",
    "print('########################################')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Tests for ID death cases handle ###################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Walds test\n",
      "MLE for March data  2.739130434782609\n",
      "Guess mean  4.95\n",
      "Standard Error  0.3450979970953814\n",
      "Walds Statistic 6.406497817506401\n",
      "########################################\n",
      "Z test\n",
      " True Variance  11.38339920948616\n",
      " Sample Mean  2.739130434782609\n",
      " Guess  4.95\n",
      " z_statistic  3.1426141089067876\n",
      "########################################\n",
      "T-test\n",
      " Corrected Sample Standard Deviation 3.3739293426931987\n",
      " Sample Mean  2.739130434782609\n",
      " Guess  4.95\n",
      " t_statistic  3.1426141089067876\n",
      "########################################\n",
      "Walds - 2 sample test\n",
      " Standard Error Estimate 0.6054689319851547\n",
      " Delta Estimate  2.2108695652173913\n",
      " w_stat  3.651499603734579\n",
      "########################################\n",
      "2 sample unpaired t-test \n",
      " Corrected Variance March 11.38339920948616\n",
      " Corrected Variance Feb 28.99736842105264\n",
      " D bar 2.2108695652173913\n",
      " t_statistic  1.585352274044677\n",
      "########################################\n"
     ]
    }
   ],
   "source": [
    "handle = 'ID deaths'\n",
    "mean_feb = np.mean(feb_data[handle])\n",
    "\n",
    "## Using mean_feb as guess for mean_march ##\n",
    "\n",
    "# Wald's test # \n",
    "# w = (theta_hat - theta_0)/ se_hat(theta_hat)\n",
    "# theta_hat is estimator of theta\n",
    "\n",
    "# Null Hypothesis : mean_march = mean_feb\n",
    "# Alternate Hypothesis : mean_march != mean_feb\n",
    "\n",
    "# Assuming the distribution of march data to be poisson. MLE_mean = Sample_mean\n",
    "\n",
    "sample_mean_march = np.mean(march_data[handle])\n",
    "\n",
    "standard_error_estimate = np.sqrt(sample_mean_march/len(march_data))\n",
    "\n",
    "walds_statistic = np.abs((sample_mean_march - mean_feb)/standard_error_estimate)\n",
    "\n",
    "print('Walds test')\n",
    "print('MLE for March data ',sample_mean_march )\n",
    "print('Guess mean ', mean_feb)\n",
    "print('Standard Error ', standard_error_estimate)\n",
    "print('Walds Statistic', walds_statistic )\n",
    "\n",
    "# Reject Null Hypothesis(greater than 1.96)\n",
    "print('########################################')\n",
    "\n",
    "\n",
    "## Z-test ##\n",
    "\n",
    "# z_statistic = (sample_mean - guess)/ root(true_variance/n)\n",
    "# true variance = corrected sample standard deviation\n",
    "\n",
    "true_variance = np.sum(np.square(march_data[handle] - sample_mean_march))/(len(march_data)-1)\n",
    "\n",
    "z_statistic = np.abs((sample_mean_march - mean_feb)/(np.sqrt(true_variance)/np.sqrt(len(march_data))))\n",
    "\n",
    "print('Z test')\n",
    "print(' True Variance ', true_variance)\n",
    "print(' Sample Mean ',sample_mean_march )\n",
    "print(' Guess ', mean_feb)\n",
    "print(' z_statistic ', z_statistic)\n",
    "\n",
    "\n",
    "# Reject Null Hypothesis(greater than 1.96)\n",
    "\n",
    "print('########################################')\n",
    "\n",
    "\n",
    "## t-test ##\n",
    "\n",
    "# t_statistic = (sample_mean - guess)/ corrected_sample_standard_deviation/root(n)\n",
    "corrected_sample_SD = np.sqrt(np.sum(np.square(march_data[handle] - sample_mean_march))/(len(march_data)-1))\n",
    "\n",
    "t_statistic = np.abs((sample_mean_march - mean_feb)/(corrected_sample_SD/np.sqrt(len(march_data))))\n",
    "\n",
    "print('T-test')\n",
    "print(' Corrected Sample Standard Deviation', corrected_sample_SD)\n",
    "print(' Sample Mean ',sample_mean_march )\n",
    "print(' Guess ', mean_feb)\n",
    "print(' t_statistic ', t_statistic)\n",
    "\n",
    "# degrees of freedom : 28 + 31 -2 = 57\n",
    "# threshold = 2.002465\n",
    "\n",
    "# Reject Null Hypothesis\n",
    "\n",
    "print('########################################')\n",
    "\n",
    "## Walds - 2 sample test ##\n",
    "\n",
    "# delta = mean_march - mean_feb \n",
    "\n",
    "# w_stat = delta_hat/ SE_hat(delta_hat)\n",
    "\n",
    "# Assumption : Data is poisson distributed\n",
    "\n",
    "# Null Hypothesis : delta = 0\n",
    "# Alternate Hypothesis : delta != 0 \n",
    "\n",
    "\n",
    "sample_mean_march = np.mean(march_data[handle])\n",
    "sample_mean_feb = np.mean(feb_data[handle])\n",
    "\n",
    "delta_hat = np.abs(sample_mean_march - sample_mean_feb)\n",
    "\n",
    "SE_hat = np.sqrt(sample_mean_march/len(march_data) + sample_mean_feb/len(feb_data))\n",
    "\n",
    "w_stat = np.abs(delta_hat/SE_hat)\n",
    "\n",
    "print('Walds - 2 sample test')\n",
    "print(' Standard Error Estimate', SE_hat)\n",
    "print(' Delta Estimate ',delta_hat )\n",
    "print(' w_stat ', w_stat)\n",
    "\n",
    "# Reject Null Hypothesis\n",
    "\n",
    "print('########################################')\n",
    "\n",
    "## 2 sample unpaired t-test ##\n",
    "\n",
    "# D_bar = X_bar - Y_bar\n",
    "# t_stat = D_bar/root(corrected_var_x/n + corrected_var_y/m)\n",
    "\n",
    "corrected_variance_march = np.sum(np.square(march_data[handle] - sample_mean_march))/(len(march_data)-1)\n",
    "corrected_variance_feb =  np.sum(np.square(feb_data[handle] - sample_mean_feb))/(len(feb_data)-1)\n",
    "\n",
    "D_bar = np.abs(sample_mean_march - sample_mean_feb)\n",
    "\n",
    "t_stat = D_bar/np.sqrt(corrected_variance_march/len(march_data) + corrected_variance_feb/len(feb_data))\n",
    "\n",
    "print('2 sample unpaired t-test ')\n",
    "print(' Corrected Variance March', corrected_variance_march)\n",
    "print(' Corrected Variance Feb', corrected_variance_feb)\n",
    "print(' D bar',D_bar )\n",
    "print(' t_statistic ', t_stat)\n",
    "\n",
    "# threshold = 2.002465\n",
    "\n",
    "# Reject Null Hypothesis\n",
    "\n",
    "print('########################################')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
